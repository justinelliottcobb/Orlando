# Orlando Benchmarks

Comprehensive performance benchmarking suite comparing Orlando transducers against popular JavaScript libraries.

## Libraries Tested

- **Orlando** - WASM-powered transducers (this library)
- **Native Array** - JavaScript built-in Array.prototype methods
- **Underscore.js** - Classic utility library
- **Ramda** - Functional programming library
- **Lodash** - Modern utility library
- **Lazy.js** - Lazy evaluation library

## Quick Start

### Node.js Benchmarks

```bash
# Install dependencies
npm install

# Build Orlando for Node.js
npm run build:nodejs

# Run full benchmark suite
npm run bench:all

# Run quick benchmarks (fewer iterations)
npm run bench:quick
```

### Browser Benchmarks

```bash
# Build Orlando for web
npm run build:release

# Serve the examples directory
npx http-server examples -p 8080

# Open in browser
open http://localhost:8080/benchmark-comparison.html
```

## Benchmark Scenarios

### 1. Map â†’ Filter â†’ Take (100K items)

**Operation:** Double numbers, filter divisible by 3, take first 10

**Why this matters:**
- Tests early termination benefits
- Shows advantage of single-pass execution
- Most libraries must process all 100K items even though we only need 10

**Expected winner:** Orlando or Lazy.js (both support early termination)

---

### 2. Complex Pipeline (50K items, 10 operations)

**Operations:** Chain of 10 map/filter operations

**Why this matters:**
- Tests composition efficiency
- Shows overhead of intermediate arrays
- Real-world pipelines often have many operations

**Expected winner:** Orlando (single pass, zero intermediate arrays)

---

### 3. Early Termination (1M items, find first 5)

**Operation:** Filter by condition, take first 5 matches

**Why this matters:**
- **Massive** performance difference scenario
- Orlando stops after finding 5 matches (~685 items processed)
- Native arrays process all 1M items before slicing

**Expected winner:** Orlando by 10-20x margin

---

### 4. Object Processing (500K objects)

**Operation:** Multiple filters and map on complex objects

**Why this matters:**
- Real-world data processing scenario
- Tests performance with object allocations
- Common in ETL and data transformation pipelines

**Expected winner:** Orlando or Lazy.js

---

### 5. Simple Map (1M items)

**Operation:** Just double each number

**Why this matters:**
- Baseline comparison
- No early termination advantage
- Tests raw throughput

**Expected winner:** Native Array (least overhead for simple operations)

## Understanding the Results

### When Orlando Wins

Orlando shows **significant** advantages when:

1. **Early termination is possible** (`take`, `takeWhile`)
   - Orlando stops processing immediately
   - Native arrays must complete all operations first
   - Can be 10-20x faster!

2. **Complex pipelines** (3+ operations)
   - No intermediate array allocations
   - Single pass over data
   - Typically 2-5x faster

3. **Large datasets** (>10K items)
   - More data = bigger wins
   - Memory savings become significant

### When Native Arrays Win

Native arrays can be faster for:

1. **Single operations** on small datasets
   - Less overhead
   - JIT optimizations
   - No WASM initialization cost

2. **Simple transformations** (<100 items)
   - Orlando's setup overhead not worth it
   - Use arrays for small data!

### When to Use Each Library

| Library | Best For | Why |
|---------|----------|-----|
| **Orlando** | Large datasets, complex pipelines, early termination | WASM speed, single-pass execution |
| **Native Array** | Simple operations, small datasets, prototyping | Zero dependencies, familiar API |
| **Lazy.js** | Infinite sequences, early termination | Lazy evaluation, functional style |
| **Ramda** | Functional programming, immutability | Pure functions, composition |
| **Lodash** | General utilities, object manipulation | Comprehensive API, battle-tested |
| **Underscore** | Legacy projects, minimal size | Small footprint, simple API |

## Interpreting the Output

### Node.js Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     Orlando Transducers - Comprehensive Benchmark Suite         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Map â†’ Filter â†’ Take (100K items)
  Dataset size: 100,000 items

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Library            â”‚ Ops/sec       â”‚ Avg Time      â”‚ vs Native        â”‚ vs Orlando       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Orlando ðŸ†         â”‚ 15,234        â”‚ 0.66ms        â”‚ 4.2x faster      â”‚ -                â”‚
â”‚ Lazy.js            â”‚ 12,891        â”‚ 0.78ms        â”‚ 3.5x faster      â”‚ 1.2x slower      â”‚
â”‚ Native Array       â”‚ 3,621         â”‚ 2.76ms        â”‚ -                â”‚ 4.2x slower      â”‚
â”‚ Lodash             â”‚ 3,512         â”‚ 2.85ms        â”‚ 1.0x slower      â”‚ 4.3x slower      â”‚
â”‚ Underscore         â”‚ 3,498         â”‚ 2.86ms        â”‚ 1.0x slower      â”‚ 4.4x slower      â”‚
â”‚ Ramda              â”‚ 2,891         â”‚ 3.46ms        â”‚ 1.3x slower      â”‚ 5.2x slower      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Summary:
  âœ… Orlando is the fastest!
  âœ… 18.2% faster than Lazy.js
```

**Key metrics:**
- **Ops/sec**: Higher is better (operations per second)
- **Avg Time**: Lower is better (average execution time)
- **vs Native**: Comparison against native arrays
- **vs Orlando**: Comparison against Orlando

### Browser Output

Visual bar charts showing relative performance. Fastest library has the longest bar and is highlighted in green.

## Running Specific Benchmarks

Edit `benchmarks/comparison.js` to comment out scenarios you don't want to run:

```javascript
const scenarios = [
    // scenarioMapFilterTake,
    scenarioComplexPipeline,
    // scenarioEarlyTermination,
    // ...
];
```

## Performance Tips

Based on benchmark results:

1. **Use Orlando for:**
   - Datasets > 1000 items
   - Pipelines with 3+ operations
   - Any scenario with early termination
   - Performance-critical code

2. **Use Native Arrays for:**
   - Datasets < 100 items
   - Single operations
   - Quick prototypes
   - Code clarity over performance

3. **Use Lazy.js for:**
   - Infinite sequences
   - Early termination with functional style
   - Alternative to Orlando without WASM

## CI/CD Integration

Benchmarks can be run in CI to track performance over time:

```yaml
# .github/workflows/benchmark.yml
name: Benchmarks

on: [push, pull_request]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - run: npm install
      - run: npm run build:nodejs
      - run: npm run bench:quick
```

## Contributing

To add new benchmarks:

1. Add scenario to `scenarios` array in `comparison.js`
2. Include all libraries for fair comparison
3. Use realistic data and operations
4. Document what the benchmark tests
5. Run benchmarks on multiple machines

## Troubleshooting

### "Cannot find module '../pkg/orlando.js'"

Build Orlando for Node.js first:
```bash
npm run build:nodejs
```

### Benchmarks are too slow

Use quick mode for faster iteration:
```bash
npm run bench:quick
```

### Results vary widely between runs

- Close other applications
- Run benchmarks multiple times
- Use more iterations (edit `ITERATIONS` in comparison.js)
- Disable CPU throttling

### Memory issues with large datasets

Reduce dataset sizes in the scenarios or increase Node.js memory:
```bash
node --max-old-space-size=4096 benchmarks/comparison.js
```

## Sample Results

See [BENCHMARK_RESULTS.md](./BENCHMARK_RESULTS.md) for sample output from various environments.
